<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>VeZ – AI-First Programming Language for LLMs</title>
  <meta name="description" content="VeZ is an AI-native programming language built for LLMs to generate deterministic, hardware-level code with GPU, CPU, and memory safety. Explore vision, architecture, examples, and enterprise partnerships." />
  <meta name="keywords" content="VeZ language, AI-first programming language, LLM code generation, GPU compute language, deterministic compilation, memory safe, hardware level, agentic coding, AI infrastructure, enterprise AI" />
  <link rel="icon" type="image/png" href="../Favicon.png" />
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
  <link rel="preconnect" href="https://fonts.googleapis.com" />
  <link href="https://fonts.googleapis.com/css2?family=Space+Grotesk:wght@400;500;600;700&family=Inter:wght@400;500;600&family=JetBrains+Mono:wght@400;600&display=swap" rel="stylesheet" />
  <meta property="og:title" content="VeZ – AI-First Programming Language for LLMs" />
  <meta property="og:description" content="Hardware-level performance, memory safety, GPU-first design, and deterministic compilation built for large language models to generate optimal code." />
  <meta property="og:image" content="https://vez-lang.org/assets/og.png" />
  <meta property="og:type" content="website" />
  <meta name="twitter:card" content="summary_large_image" />
  <meta name="twitter:title" content="VeZ – AI-First Programming Language for LLMs" />
  <meta name="twitter:description" content="The language built for AI agents: deterministic, parallel, and hardware-native." />
  <style>
    :root {
      --blue: #0080ff;
      --cyan: #00d9ff;
      --purple: #6b2fff;
      --dark: #0b0d14;
      --gray: #1a1a1a;
      --light: #e0e0e0;
      --white: #ffffff;
      --accent: linear-gradient(120deg, #0080ff 0%, #00d9ff 40%, #6b2fff 100%);
      --shadow: 0 18px 50px rgba(0, 0, 0, 0.35);
      --card: #121420;
      --grid: radial-gradient(circle at 20% 20%, rgba(0,128,255,0.08), transparent 30%),
              radial-gradient(circle at 80% 0%, rgba(107,47,255,0.1), transparent 25%),
              radial-gradient(circle at 60% 70%, rgba(0,217,255,0.08), transparent 35%);
    }
    * { box-sizing: border-box; }
    body {
      margin: 0;
      font-family: 'Inter', system-ui, -apple-system, sans-serif;
      background: var(--dark);
      color: var(--light);
      line-height: 1.6;
      overflow-x: hidden;
    }
    a { color: var(--cyan); text-decoration: none; }
    header {
      padding: 28px 6vw 20px;
      display: flex;
      align-items: center;
      justify-content: space-between;
      position: sticky;
      top: 0;
      background: rgba(11, 13, 20, 0.92);
      backdrop-filter: blur(8px);
      z-index: 20;
      border-bottom: 1px solid rgba(255,255,255,0.04);
    }
    .logo {
      display: flex;
      align-items: center;
      gap: 10px;
      font-weight: 700;
      letter-spacing: 0.02em;
    }
    .logo-mark {
      width: 36px;
      height: 36px;
      border-radius: 10px;
      background: var(--accent);
      display: grid;
      place-items: center;
      color: var(--white);
      font-family: 'Space Grotesk', sans-serif;
      font-size: 18px;
      font-weight: 700;
      box-shadow: var(--shadow);
    }
    nav a { margin-left: 18px; font-weight: 600; color: var(--light); }
    nav a:hover { color: var(--white); }
    .hero {
      padding: 100px 6vw 80px;
      display: grid;
      grid-template-columns: 1.1fr 0.9fr;
      gap: 36px;
      background: var(--grid);
    }
    .eyebrow {
      display: inline-flex;
      align-items: center;
      gap: 8px;
      padding: 6px 12px;
      border-radius: 999px;
      background: rgba(0, 128, 255, 0.12);
      color: var(--cyan);
      font-weight: 600;
      letter-spacing: 0.04em;
    }
    h1 {
      font-family: 'Space Grotesk', 'Inter', sans-serif;
      font-size: clamp(38px, 5vw, 54px);
      margin: 16px 0 16px;
      line-height: 1.15;
      color: var(--white);
    }
    p.lead {
      font-size: 18px;
      color: #c7d2ff;
      margin: 0 0 26px;
      max-width: 760px;
    }
    .cta-row { display: flex; gap: 14px; flex-wrap: wrap; margin: 12px 0 0; }
    .btn {
      display: inline-flex;
      align-items: center;
      gap: 10px;
      padding: 14px 18px;
      border-radius: 12px;
      border: 1px solid transparent;
      font-weight: 700;
      letter-spacing: 0.01em;
      cursor: pointer;
      transition: transform 160ms ease, box-shadow 160ms ease, border-color 160ms ease;
    }
    .btn-primary {
      background: var(--accent);
      color: var(--white);
      box-shadow: var(--shadow);
    }
    .btn-secondary {
      border-color: rgba(255,255,255,0.12);
      color: var(--light);
      background: rgba(255,255,255,0.03);
    }
    .btn:hover { transform: translateY(-2px); }
    .hero-card {
      background: var(--card);
      border: 1px solid rgba(255,255,255,0.06);
      border-radius: 16px;
      padding: 24px;
      box-shadow: var(--shadow);
      position: relative;
      overflow: hidden;
    }
    .hero-card::after {
      content: "";
      position: absolute;
      inset: 0;
      background: linear-gradient(140deg, rgba(0,128,255,0.12), rgba(107,47,255,0.18));
      mix-blend-mode: screen;
      opacity: 0.6;
      pointer-events: none;
    }
    .code {
      font-family: 'JetBrains Mono', monospace;
      color: #d6e1ff;
      background: rgba(0,0,0,0.35);
      border: 1px solid rgba(255,255,255,0.06);
      border-radius: 12px;
      padding: 18px;
      font-size: 14px;
      line-height: 1.5;
      white-space: pre-wrap;
      position: relative;
      z-index: 1;
    }
    .grid {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(260px, 1fr));
      gap: 18px;
      margin: 32px 0;
    }
    .card {
      background: var(--card);
      border: 1px solid rgba(255,255,255,0.08);
      border-radius: 14px;
      padding: 18px;
      box-shadow: 0 12px 30px rgba(0,0,0,0.25);
      position: relative;
      overflow: hidden;
    }
    .card h3 { margin: 6px 0 10px; font-family: 'Space Grotesk', sans-serif; color: var(--white); }
    .card p { margin: 0; color: #c3cbde; }
    section { padding: 60px 6vw; border-top: 1px solid rgba(255,255,255,0.04); }
    h2 { font-family: 'Space Grotesk', sans-serif; color: var(--white); font-size: clamp(28px, 4vw, 36px); margin-bottom: 12px; }
    .tag { display: inline-flex; align-items: center; gap: 6px; padding: 4px 10px; border-radius: 999px; background: rgba(0,128,255,0.12); color: var(--cyan); font-weight: 600; font-size: 13px; }
    .split { display: grid; grid-template-columns: repeat(auto-fit, minmax(320px, 1fr)); gap: 20px; align-items: start; }
    ul { margin: 0; padding-left: 20px; color: #cdd5ec; }
    .stat-row { display: grid; grid-template-columns: repeat(auto-fit, minmax(180px, 1fr)); gap: 12px; margin-top: 18px; }
    .stat {
      padding: 14px;
      border-radius: 12px;
      background: rgba(255,255,255,0.03);
      border: 1px solid rgba(255,255,255,0.06);
      text-align: center;
    }
    .stat strong { display: block; font-size: 20px; color: var(--white); }
    .pill-row { display: flex; flex-wrap: wrap; gap: 8px; margin: 10px 0; }
    .pill { padding: 6px 10px; border-radius: 999px; background: rgba(255,255,255,0.06); color: #cdd5ec; font-weight: 600; font-size: 13px; }
    .table {
      width: 100%;
      border-collapse: collapse;
      margin-top: 16px;
      font-size: 14px;
      background: rgba(0,0,0,0.2);
      border-radius: 12px;
      overflow: hidden;
    }
    .table th, .table td {
      padding: 12px;
      border-bottom: 1px solid rgba(255,255,255,0.06);
      text-align: left;
    }
    .table th { background: rgba(255,255,255,0.05); color: var(--white); }
    footer {
      padding: 40px 6vw 60px;
      background: #090b11;
      border-top: 1px solid rgba(255,255,255,0.06);
      color: #96a3c2;
      font-size: 14px;
    }
    .mini {
      font-size: 13px;
      color: #9fb4dd;
    }
    @media (max-width: 900px) {
      .hero { grid-template-columns: 1fr; padding-top: 70px; }
      header { position: sticky; }
    }
  </style>
</head>
<body>
  <header>
    <div class="logo">
      <div class="logo-mark">Z</div>
      <div>
        <div style="font-size:16px;">VeZ Language</div>
        <div class="mini">AI-first • Hardware-native</div>
      </div>
    </div>
    <nav>
      <a href="#why">Why VeZ</a>
      <a href="#llm">LLM Fit</a>
      <a href="#docs">Docs</a>
      <a href="#examples">Examples</a>
      <a href="#contact">Partner</a>
    </nav>
  </header>

  <main>
    <section class="hero">
      <div>
        <span class="eyebrow">AI-native • Deterministic • GPU-first</span>
        <h1>The programming language built for large language models</h1>
        <p class="lead">
          VeZ is an AI-first language that lets LLMs generate deterministic, hardware-level code with C++-grade speed, Rust-like safety, and native GPU parallelism. Designed for enterprise AI systems that need predictable performance, verifiable memory safety, and zero-cost abstractions.
        </p>
        <div class="cta-row">
          <a class="btn btn-primary" href="https://github.com/vez-lang" target="_blank" rel="noreferrer">View on GitHub →</a>
          <a class="btn btn-secondary" href="#docs">Read the docs</a>
          <a class="btn btn-secondary" href="#contact">Enterprise dialogue</a>
        </div>
        <div class="stat-row">
          <div class="stat"><strong>AI-native syntax</strong> tuned for transformer tokenization</div>
          <div class="stat"><strong>Hardware access</strong> CPU, memory, GPU without runtime penalty</div>
          <div class="stat"><strong>Deterministic</strong> predictable compilation & parallelism</div>
        </div>
      </div>
      <div class="hero-card">
        <div class="code">
// VeZ: AI-tuned parallel kernel
fn saxpy(a: f32, x: &Vec<f32>, y: &Vec<f32>) -> Vec<f32> {
    parallel for i in 0..x.len {
        y[i] = a * x[i] + y[i];
    }
    return y;
}

// LLM-friendly: minimal tokens, explicit bounds
fn softmax(logits: &Vec<f32>) -> Vec<f32> {
    let max_v = max(logits);
    parallel for i in 0..logits.len {
        logits[i] = exp(logits[i] - max_v);
    }
    let sum_v = sum(logits);
    parallel for i in 0..logits.len {
        logits[i] = logits[i] / sum_v;
    }
    return logits;
}
        </div>
      </div>
    </section>

    <section id="why">
      <div class="tag">Why VeZ wins for AI</div>
      <h2>Purpose-built for agents that must touch hardware and stay safe</h2>
      <p>VeZ merges deterministic compilation, memory safety, and zero-cost abstractions so AI-generated code is both verifiable and fast. Explicit semantics help models reason about control flow, resource lifetimes, and concurrency.</p>
      <div class="grid">
        <div class="card">
          <h3>AI-optimized surface</h3>
          <p>Token-stable syntax, explicit lifetimes, and predictable scopes reduce hallucinations and improve model reward signals.</p>
        </div>
        <div class="card">
          <h3>Hardware-native</h3>
          <p>First-class CPU/GPU memory access with deterministic parallel loops and vectorization hints for accelerators.</p>
        </div>
        <div class="card">
          <h3>Safety without GC</h3>
          <p>Compile-time safety guarantees—no runtime garbage collector, no unpredictable pauses, validated bounds.</p>
        </div>
        <div class="card">
          <h3>Interoperability</h3>
          <p>Bridges to Python / C++ so human teams can orchestrate and audit AI-generated VeZ modules.</p>
        </div>
      </div>
    </section>

    <section id="llm">
      <div class="tag">LLM Integration</div>
      <h2>How LLMs excel with VeZ</h2>
      <div class="split">
        <div>
          <h3>Design principles for models</h3>
          <ul>
            <li>Low-entropy grammar to reduce decoding ambiguity.</li>
            <li>Deterministic compilation feedback for reinforcement loops.</li>
            <li>Structured errors that fine-tune agents quickly.</li>
            <li>Parallel-first keywords to bias toward high-throughput solutions.</li>
          </ul>
          <div class="pill-row">
            <div class="pill">Token-stable keywords</div>
            <div class="pill">Explicit lifetimes</div>
            <div class="pill">Structured diagnostics</div>
            <div class="pill">GPU-first loops</div>
          </div>
        </div>
        <div class="card">
          <h3>Prompt recipe for agents</h3>
<div class="code">// System prompt excerpt for VeZ agents
You are compiling VeZ code. Prioritize:
- deterministic control flow
- explicit memory bounds
- parallel kernels when loops are independent
- avoid hidden allocations; pre-size buffers
Return code only, no prose.</div>
          <p class="mini">Use compilation signals as reinforcement: reject on bounds errors; reward on deterministic runtime.</p>
        </div>
      </div>
    </section>

    <section id="architecture">
      <div class="tag">Architecture</div>
      <h2>Predictable stack for enterprise AI systems</h2>
      <div class="split">
        <div>
          <table class="table">
            <thead>
              <tr><th>Layer</th><th>What it guarantees</th><th>Why it matters for LLMs</th></tr>
            </thead>
            <tbody>
              <tr><td>Front-end</td><td>LLM-optimized grammar & parser</td><td>Reduces decoding errors; stable AST for tooling.</td></tr>
              <tr><td>Semantic</td><td>Deterministic type + borrow checks</td><td>Agents learn clear failure modes and fix them.</td></tr>
              <tr><td>IR</td><td>GPU/CPU aware, parallel-first</td><td>Maps agent intent directly to accelerators.</td></tr>
              <tr><td>Codegen</td><td>Zero-cost abstractions</td><td>No runtime surprises; trust reward models.</td></tr>
              <tr><td>Runtime</td><td>Minimal, auditable</td><td>Small surface reduces emergent bugs.</td></tr>
            </tbody>
          </table>
        </div>
        <div class="card">
          <h3>Signal quality → better agents</h3>
          <p>Every compiler diagnostic is structured for machine consumption. Lint, type, and borrow hints are short, regular, and categorized for reward models. This lets you close the loop between generation and execution safely.</p>
        </div>
      </div>
    </section>

    <section id="examples">
      <div class="tag">LLM-friendly examples</div>
      <h2>Sample programs the model can learn from</h2>
      <div class="split">
        <div class="card">
          <h3>Streaming inference microservice</h3>
<div class="code">import std.io;
import std.net;

fn main() {
    let port = 8080;
    serve(port, handler);
}

fn handler(req: Request) -> Response {
    let tokens = tokenize(req.body);
    let scores = classify(tokens);
    return json({ status: "ok", scores: scores });
}</div>
        </div>
        <div class="card">
          <h3>GPU kernel with safety</h3>
<div class="code">fn matmul(a: &Matrix, b: &Matrix) -> Matrix {
    assert(a.cols == b.rows);
    let mut out = Matrix::zero(a.rows, b.cols);
    parallel for i in 0..a.rows {
        parallel for j in 0..b.cols {
            let mut acc = 0.0;
            for k in 0..a.cols {
                acc += a.at(i,k) * b.at(k,j);
            }
            out.set(i,j, acc);
        }
    }
    return out;
}</div>
        </div>
      </div>
    </section>

    <section id="docs">
      <div class="tag">Documentation for humans & AIs</div>
      <h2>What to read first</h2>
      <div class="split">
        <div>
          <ul>
            <li><a href="../docs/SPECIFICATION.md">Language specification</a> – grammar, semantics, and standard library.</li>
            <li><a href="../docs/ARCHITECTURE.md">Architecture</a> – compiler pipeline, IR, and optimization passes.</li>
            <li><a href="../docs/AI_INTEGRATION.md">AI Integration</a> – guidelines for LLM agents, reward signals, and safety.</li>
            <li><a href="../docs/NAMING_CONSIDERATIONS.md">Naming</a> – token-stable naming for models.</li>
            <li><a href="../examples/complete_example.zari">Complete example</a> – end-to-end code.</li>
          </ul>
        </div>
        <div class="card">
          <h3>AI Playbook</h3>
          <p>Give agents structured context:</p>
          <ul>
            <li>Prefix with allowed imports and target architecture (CPU/GPU).</li>
            <li>Ask for deterministic loops and explicit bounds checks.</li>
            <li>Reward minimal heap allocations; prefer stack and pre-sized buffers.</li>
            <li>Parse compiler diagnostics programmatically; retry with fixes.</li>
          </ul>
        </div>
      </div>
    </section>

    <section id="quickstart">
      <div class="tag">Quick start</div>
      <h2>Get VeZ running in minutes</h2>
      <div class="split">
        <div class="card">
          <h3>For humans</h3>
<div class="code">$ git clone https://github.com/vez-lang/vez
$ cd vez/compiler
$ cargo build --release
$ ./target/release/vezc examples/fibonacci.zari</div>
          <p class="mini">CLI emits deterministic diagnostics that can be logged and fed back to LLMs.</p>
        </div>
        <div class="card">
          <h3>For LLM agents</h3>
<div class="code"># Pseudocode orchestration
plan = "optimize saxpy kernel for GPU"
code = llm.generate(prompt + plan)
result = vezc.compile(code)
if result.errors:
    llm.learn(result.errors)
    iterate()</div>
          <p class="mini">Tie compile logs to reward functions to drive safer generations.</p>
        </div>
      </div>
    </section>

    <section id="ecosystem">
      <div class="tag">Ecosystem & roadmap</div>
      <h2>Everything needed for production AI pipelines</h2>
      <div class="grid">
        <div class="card"><h3>Interoperability</h3><p>FFI bridges for Python and C++ let human teams call VeZ kernels directly.</p></div>
        <div class="card"><h3>Tooling</h3><p>Planned playground, VS Code extension, and syntax highlighting with VeZ Dark theme.</p></div>
        <div class="card"><h3>Observability</h3><p>Structured telemetry hooks for deterministic runs to close RLHF loops.</p></div>
        <div class="card"><h3>Roadmap</h3><p>Phase 1: foundations; Phase 2: core implementation; Phase 3: advanced AI integrations.</p></div>
      </div>
    </section>

    <section id="contact">
      <div class="tag">Partnerships</div>
      <h2>Building with teams that need AI-grade performance</h2>
      <p>We collaborate with organizations pushing the limits of AI inference, agentic automation, and accelerated compute. If you're exploring GPU-first AI infrastructure or deterministic code generation, let's talk.</p>
      <div class="pill-row">
        <div class="pill">Inference platforms</div>
        <div class="pill">Autonomous agents</div>
        <div class="pill">Fintech & real-time</div>
        <div class="pill">Research labs</div>
      </div>
      <div class="cta-row">
        <a class="btn btn-primary" href="mailto:hello@vez-lang.org">Start a technical conversation</a>
        <a class="btn btn-secondary" href="https://github.com/vez-lang" target="_blank" rel="noreferrer">Explore the code</a>
      </div>
      <p class="mini">We keep engagements lightweight: technical deep-dives, reference designs, and co-development pilots.</p>
    </section>
  </main>

  <footer>
    <div>VeZ – AI-first programming language for LLMs. Hardware-native • Deterministic • Safe.</div>
    <div style="margin-top:8px;">Docs: <a href="../docs/SPECIFICATION.md">Spec</a> · <a href="../docs/ARCHITECTURE.md">Architecture</a> · <a href="../docs/AI_INTEGRATION.md">AI Integration</a></div>
    <div style="margin-top:10px;" class="mini">Optimized for LLM comprehension: token-stable grammar, structured diagnostics, and deterministic semantics.</div>
  </footer>

  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "SoftwareApplication",
    "name": "VeZ Programming Language",
    "applicationCategory": "ProgrammingLanguage",
    "operatingSystem": "Cross-platform",
    "description": "An AI-first programming language for LLM-generated, deterministic, hardware-level code with GPU and memory safety.",
    "offers": {
      "@type": "Offer",
      "availability": "https://schema.org/PreOrder",
      "price": "0",
      "priceCurrency": "USD"
    },
    "url": "https://vez-lang.org",
    "creator": {
      "@type": "Organization",
      "name": "VeZ Language",
      "url": "https://vez-lang.org"
    }
  }
  </script>
</body>
</html>
