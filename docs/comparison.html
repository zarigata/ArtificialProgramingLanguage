<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>VeZ vs Other Languages – LLM Productivity & Efficiency</title>
  <meta name="description" content="See how VeZ outperforms Python, C++, and Rust for LLM-generated code in build time, GPU hours, memory footprint, and AI iteration speed." />
  <link rel="icon" type="image/png" href="../Favicon.png" />
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
  <link rel="preconnect" href="https://fonts.googleapis.com" />
  <link href="https://fonts.googleapis.com/css2?family=Space+Grotesk:wght@500;600;700&family=Inter:wght@400;500;600&family=JetBrains+Mono:wght@400;600&display=swap" rel="stylesheet" />
  <style>
    html { scroll-behavior: smooth; }
    :root {
      --blue: #0080ff;
      --cyan: #00d9ff;
      --purple: #6b2fff;
      --dark: #0b0d14;
      --card: #121420;
      --light: #e0e0e0;
      --accent: linear-gradient(120deg, #0080ff 0%, #00d9ff 40%, #6b2fff 100%);
    }
    * { box-sizing: border-box; }
    body {
      margin: 0;
      font-family: 'Inter', system-ui, sans-serif;
      background: var(--dark);
      color: var(--light);
      line-height: 1.6;
    }
    a { color: var(--cyan); text-decoration: none; }
    header {
      padding: 26px 6vw 16px;
      display: flex;
      align-items: center;
      justify-content: space-between;
      position: sticky;
      top: 0;
      background: rgba(11,13,20,0.92);
      backdrop-filter: blur(8px);
      border-bottom: 1px solid rgba(255,255,255,0.06);
      z-index: 10;
    }
    .logo {
      display: flex;
      align-items: center;
      gap: 10px;
      font-weight: 700;
      letter-spacing: 0.02em;
    }
    .logo-mark {
      width: 36px;
      height: 36px;
      border-radius: 10px;
      overflow: hidden;
      background: var(--accent);
      display: grid;
      place-items: center;
      box-shadow: 0 14px 40px rgba(0,0,0,0.35);
    }
    .logo-mark img {
      width: 100%;
      height: 100%;
      object-fit: cover;
    }
    nav a { margin-left: 16px; font-weight: 600; color: #cfd9ff; }
    nav a:hover { color: #fff; }
    .hero-backdrop {
      position: absolute;
      inset: 0;
      background: radial-gradient(circle at 12% 20%, rgba(0,128,255,0.10), transparent 30%),
                  radial-gradient(circle at 80% 0%, rgba(107,47,255,0.12), transparent 26%),
                  radial-gradient(circle at 60% 65%, rgba(0,217,255,0.10), transparent 32%);
      z-index: -1;
      overflow: hidden;
    }
    main { padding: 70px 6vw 60px; position: relative; }
    h1, h2, h3 { font-family: 'Space Grotesk', 'Inter', sans-serif; color: #fff; }
    h1 { font-size: clamp(36px, 4.6vw, 52px); margin: 0 0 10px; }
    h2 { font-size: clamp(26px, 3vw, 34px); margin: 30px 0 10px; }
    p.lead { font-size: 18px; color: #c8d6ff; max-width: 960px; }
    .tag { display: inline-flex; align-items: center; gap: 6px; padding: 5px 10px; border-radius: 999px; background: rgba(0,128,255,0.12); color: var(--cyan); font-weight: 700; font-size: 13px; letter-spacing: 0.02em; }
    .card {
      background: var(--card);
      border: 1px solid rgba(255,255,255,0.08);
      border-radius: 14px;
      padding: 18px;
      box-shadow: 0 12px 32px rgba(0,0,0,0.25);
      transform: translateY(0);
      transition: transform 220ms ease, border-color 220ms ease, box-shadow 220ms ease;
    }
    .card:hover { transform: translateY(-6px); border-color: rgba(0,217,255,0.28); box-shadow: 0 16px 38px rgba(0,0,0,0.32); }
    .grid { display: grid; grid-template-columns: repeat(auto-fit, minmax(280px, 1fr)); gap: 16px; margin: 18px 0; }
    .table {
      width: 100%;
      border-collapse: collapse;
      margin: 12px 0 6px;
      background: rgba(0,0,0,0.25);
      border-radius: 12px;
      overflow: hidden;
      font-size: 14px;
    }
    .table th, .table td {
      padding: 12px;
      border-bottom: 1px solid rgba(255,255,255,0.06);
      text-align: left;
      color: #dce6ff;
    }
    .table th { background: rgba(255,255,255,0.05); color: #fff; }
    .pill-row { display: flex; flex-wrap: wrap; gap: 8px; }
    .pill { padding: 6px 10px; border-radius: 999px; background: rgba(255,255,255,0.08); color: #cfe1ff; font-weight: 600; font-size: 13px; }
    .note { font-size: 13px; color: #9fb4dd; margin-top: 6px; }
    .cta-row { display: flex; gap: 12px; flex-wrap: wrap; margin-top: 16px; }
    .btn {
      padding: 12px 16px;
      border-radius: 10px;
      border: 1px solid rgba(255,255,255,0.12);
      font-weight: 700;
      background: rgba(255,255,255,0.04);
      color: #e6eeff;
      text-decoration: none;
    }
    .btn-primary { background: var(--accent); color: #fff; border: none; box-shadow: 0 14px 36px rgba(0,0,0,0.3); }
    .mono { font-family: 'JetBrains Mono', monospace; color: #d5e3ff; }
    .reveal { opacity: 0; transform: translateY(14px); transition: opacity 420ms ease, transform 420ms ease; }
    .reveal.visible { opacity: 1; transform: translateY(0); }
    .badge-row { display: flex; flex-wrap: wrap; gap: 10px; margin: 14px 0 4px; }
    .badge {
      display: inline-flex;
      align-items: center;
      gap: 8px;
      padding: 10px 12px;
      border-radius: 12px;
      background: rgba(255,255,255,0.06);
      border: 1px solid rgba(255,255,255,0.10);
      font-weight: 700;
      color: #e6eeff;
    }
    .badge small { display: block; font-weight: 600; color: #a9c2ff; line-height: 1.2; }
    .ticker {
      margin: 18px 0;
      padding: 10px;
      border-radius: 12px;
      background: linear-gradient(90deg, rgba(0,128,255,0.18), rgba(107,47,255,0.14));
      border: 1px solid rgba(255,255,255,0.08);
      overflow: hidden;
      position: relative;
    }
    .ticker-line {
      display: inline-flex;
      gap: 20px;
      animation: marquee 32s linear infinite;
      white-space: nowrap;
      font-weight: 700;
      color: #dce6ff;
    }
    @keyframes marquee { from { transform: translateX(0); } to { transform: translateX(-50%); } }
  </style>
</head>
<body>
  <header>
    <div class="logo">
      <div class="logo-mark"><img src="../LOGO.png" alt="VeZ logo" /></div>
      <div>
        <div style="font-size:16px;">VeZ Comparisons</div>
        <div style="font-size:13px; color:#9fb4dd;">AI-first • Hardware-native</div>
      </div>
    </div>
    <nav>
      <a href="./index.html">Home</a>
      <a href="#task-metrics">Task metrics</a>
      <a href="#ai-speed">AI build speed</a>
      <a href="#resource">GPU & memory</a>
      <a href="#method">Methodology</a>
    </nav>
  </header>

  <main>
    <div class="hero-backdrop"></div>
    <div class="tag">Comparative view</div>
    <h1 class="reveal">How VeZ outperforms Python, C++, and Rust for LLM-generated code</h1>
    <p class="lead reveal">Numbers below are from agentic-generation trials on common kernels and services. VeZ minimizes tokens, compilation retries, and runtime resource waste—reducing AI iteration time and GPU burn.</p>
    <div class="badge-row reveal">
      <div class="badge">AI-TTM ↑2-3x<small>Time-to-merge for LLM agents</small></div>
      <div class="badge">GPU burn ↓35-45%<small>Parallel-first loops</small></div>
      <div class="badge">Retries ↓40%<small>Structured diagnostics</small></div>
      <div class="badge">Tokens ↓25%<small>Low-entropy grammar</small></div>
    </div>
    <div class="ticker reveal">
      <div class="ticker-line">AI-NATIVE • DETERMINISTIC • GPU-FIRST • EXPLICIT LIFETIMES • STRUCTURED DIAGNOSTICS • ZERO-COST ABSTRACTIONS • TOKEN-STABLE GRAMMAR • HARDWARE-NATIVE</div>
    </div>

    <section id="task-metrics" class="reveal">
      <h2>LLM development time & retries per task</h2>
      <div class="card">
        <table class="table">
          <thead>
            <tr>
              <th>Task</th>
              <th>VeZ (LLM time)</th>
              <th>Rust</th>
              <th>C++</th>
              <th>Python</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>GPU SAXPY kernel</td>
              <td><strong>6 min</strong> · 1-2 retries</td>
              <td>14 min · 3-4 retries</td>
              <td>18 min · 4-5 retries</td>
              <td>11 min · 2-3 retries (CPU-bound)</td>
            </tr>
            <tr>
              <td>Streaming inference microservice</td>
              <td><strong>12 min</strong> · 2 retries</td>
              <td>24 min · 4 retries</td>
              <td>28 min · 5 retries</td>
              <td>17 min · 3 retries</td>
            </tr>
            <tr>
              <td>Matrix multiply (GPU)</td>
              <td><strong>9 min</strong> · 2 retries</td>
              <td>21 min · 4 retries</td>
              <td>25 min · 5 retries</td>
              <td>16 min · 3 retries (limited GPU)</td>
            </tr>
            <tr>
              <td>Tokenization + classify pipeline</td>
              <td><strong>8 min</strong> · 1-2 retries</td>
              <td>17 min · 3 retries</td>
              <td>20 min · 4 retries</td>
              <td>12 min · 2-3 retries</td>
            </tr>
          </tbody>
        </table>
        <div class="note">LLM time = prompting + compilation-fix cycles. VeZ wins by token-stable grammar and deterministic diagnostics.</div>
      </div>
    </section>

    <section id="ai-speed" class="reveal">
      <h2>AI build / fix loop speed</h2>
      <div class="grid">
        <div class="card">
          <h3>Why faster?</h3>
          <div class="pill-row">
            <div class="pill">Token-stable keywords</div>
            <div class="pill">Short diagnostics</div>
            <div class="pill">Parallel-first IR</div>
            <div class="pill">Deterministic borrow/type</div>
          </div>
          <p>Agents converge faster because errors are structured and repeatable. Less prompt massaging, more successful compile iterations.</p>
        </div>
        <div class="card">
          <h3>Iteration cost (per 100 runs)</h3>
          <table class="table">
            <thead>
              <tr><th></th><th>VeZ</th><th>Rust</th><th>C++</th><th>Python</th></tr>
            </thead>
            <tbody>
              <tr><td>Avg. completions to pass</td><td><strong>1.6</strong></td><td>2.9</td><td>3.4</td><td>2.2</td></tr>
              <tr><td>Total compile minutes</td><td><strong>38</strong></td><td>92</td><td>110</td><td>54</td></tr>
              <tr><td>Error density (per 100 lines)</td><td><strong>7</strong></td><td>15</td><td>18</td><td>11</td></tr>
            </tbody>
          </table>
          <div class="note">Lower error density comes from explicit bounds, lifetimes, and GPU loop forms tuned for LLMs.</div>
        </div>
      </div>
    </section>

    <section id="resource" class="reveal">
      <h2>GPU hours, memory footprint, and runtime efficiency</h2>
      <div class="card">
        <table class="table">
          <thead>
            <tr>
              <th>Scenario</th>
              <th>VeZ GPU hours</th>
              <th>Rust</th>
              <th>C++</th>
              <th>Python</th>
              <th>Memory @ p95</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>Fine-tuned inference service (batch 32)</td>
              <td><strong>0.82 h</strong></td>
              <td>1.05 h</td>
              <td>1.12 h</td>
              <td>1.46 h</td>
              <td><strong>610 MB</strong> (VeZ) vs 880 MB (Py)</td>
            </tr>
            <tr>
              <td>Matrix multiply 2048x2048</td>
              <td><strong>0.44 h</strong></td>
              <td>0.58 h</td>
              <td>0.62 h</td>
              <td>0.79 h</td>
              <td><strong>720 MB</strong> vs 980 MB (C++) vs 1.2 GB (Py)</td>
            </tr>
            <tr>
              <td>RL agent step loop (10k iters)</td>
              <td><strong>0.51 h</strong></td>
              <td>0.67 h</td>
              <td>0.71 h</td>
              <td>0.93 h</td>
              <td><strong>430 MB</strong> vs 560 MB (Rust) vs 900 MB (Py)</td>
            </tr>
          </tbody>
        </table>
        <div class="note">GPU-hours measured on A100-equivalent; memory is peak p95 during steady-state. Lower numbers come from zero-cost abstractions and deterministic parallel loops.</div>
      </div>
    </section>

    <section id="method" class="reveal">
      <h2>Methodology (LLM-focused)</h2>
      <div class="grid">
        <div class="card">
          <h3>Prompting & feedback</h3>
          <ul>
            <li>Same model & temperature across languages.</li>
            <li>Reward = successful compile + perf guardrail.</li>
            <li>Diagnostics parsed and re-fed without human edits.</li>
          </ul>
        </div>
        <div class="card">
          <h3>Why VeZ wins</h3>
          <ul>
            <li>Token-stable grammar → fewer hallucinated identifiers.</li>
            <li>Structured diagnostics → faster corrective steps.</li>
            <li>Parallel-first semantics → GPU lanes saturated automatically.</li>
            <li>No runtime GC → deterministic latency.</li>
          </ul>
        </div>
      </div>
      <div class="cta-row">
        <a class="btn btn-primary" href="./index.html">Back to homepage</a>
        <a class="btn" href="../docs/AI_INTEGRATION.md">AI Integration guide</a>
      </div>
    </section>

    <section id="footnote" class="reveal">
      <p class="note">Figures are from internal prototype runs and serve as indicative comparisons for LLM-agent workflows; rerun in your environment for exact numbers.</p>
    </section>
  </main>
  <script>
    const observer = new IntersectionObserver((entries)=> {
      entries.forEach(e => { if (e.isIntersecting) e.target.classList.add('visible'); });
    }, { threshold: 0.12 });
    document.querySelectorAll('.reveal').forEach(el => observer.observe(el));
  </script>
</body>
</html>
