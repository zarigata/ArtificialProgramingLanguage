// VeZ ROCm/AMD GPU Example
// Demonstrates AMD GPU compute using HIP kernels

@rocm(arch="gfx1100", workgroup=256)
def vector_add(a: &f32, b: &f32, c: &mut f32, n: usize):
    let idx = @global_idx()
    if idx < n:
        c[idx] = a[idx] + b[idx]

@rocm(arch="gfx1100", workgroup=256)
def vector_mul(a: &f32, b: &f32, c: &mut f32, n: usize):
    let idx = @global_idx()
    if idx < n:
        c[idx] = a[idx] * b[idx]

@rocm(arch="gfx940", workgroup=256)
def saxpy(a: f32, x: &f32, y: &f32, out: &mut f32, n: usize):
    let idx = @global_idx()
    if idx < n:
        out[idx] = a * x[idx] + y[idx]

@rocm(arch="gfx940", workgroup=16, grid=(64, 64))
def matrix_mul(A: &f32, B: &f32, C: &mut f32, M: usize, N: usize, K: usize):
    let row = @global_idx_x()
    let col = @global_idx_y()
    
    if row < M and col < N:
        let mut sum = 0.0
        for k in range(K):
            sum = sum + A[row * K + k] * B[k * N + col]
        C[row * N + col] = sum

@rocm(arch="gfx940", workgroup=256, shared=4096)
def reduce_sum(data: &f32, result: &mut f32, n: usize):
    let local_idx = @local_idx()
    let global_idx = @global_idx()
    
    @shared_memory
    var shared_data: [f32; 256]
    
    if global_idx < n:
        shared_data[local_idx] = data[global_idx]
    else:
        shared_data[local_idx] = 0.0
    
    @barrier()
    
    var stride = 128
    while stride > 0:
        if local_idx < stride:
            shared_data[local_idx] = shared_data[local_idx] + shared_data[local_idx + stride]
        stride = stride / 2
        @barrier()
    
    if local_idx == 0:
        result[@group_idx()] = shared_data[0]

@rocm(arch="gfx940", workgroup=256)
def prefix_sum(input: &f32, output: &mut f32, n: usize):
    let idx = @global_idx()
    
    if idx < n:
        var sum = 0.0
        for i in range(idx + 1):
            sum = sum + input[i]
        output[idx] = sum

@rocm(arch="gfx940", workgroup=(16, 16))
def transpose(input: &f32, output: &mut f32, rows: usize, cols: usize):
    let row = @global_idx_x()
    let col = @global_idx_y()
    
    if row < rows and col < cols:
        output[col * rows + row] = input[row * cols + col]

@rocm(arch="gfx1100", workgroup=64)
def relu(input: &f32, output: &mut f32, n: usize):
    let idx = @global_idx()
    if idx < n:
        output[idx] = if input[idx] > 0.0 { input[idx] } else { 0.0 }

@rocm(arch="gfx1100", workgroup=64)
def softmax(input: &f32, output: &mut f32, n: usize):
    let idx = @global_idx()
    
    var max_val = input[0]
    for i in range(n):
        if input[i] > max_val:
            max_val = input[i]
    
    var sum = 0.0
    for i in range(n):
        sum = sum + @exp(input[i] - max_val)
    
    if idx < n:
        output[idx] = @exp(input[idx] - max_val) / sum

@rocm(arch="gfx940", workgroup=256, uses_matrix=true)
def gemm(M: usize, N: usize, K: usize, alpha: f32, A: &f32, B: &f32, beta: f32, C: &mut f32):
    let row = @global_idx_x()
    let col = @global_idx_y()
    
    if row < M and col < N:
        var sum = 0.0
        for k in range(K):
            sum = sum + A[row * K + k] * B[k * N + col]
        C[row * N + col] = alpha * sum + beta * C[row * N + col]

@rocm(arch="gfx940", workgroup=(8, 8, 8))
def conv3d(input: &f32, kernel: &f32, output: &mut f32, 
           in_channels: usize, out_channels: usize,
           depth: usize, height: usize, width: usize,
           k_depth: usize, k_height: usize, k_width: usize):
    let d = @global_idx_x()
    let h = @global_idx_y()
    let w = @global_idx_z()
    
    let out_d = depth - k_depth + 1
    let out_h = height - k_height + 1
    let out_w = width - k_width + 1
    
    if d < out_d and h < out_h and w < out_w:
        for oc in range(out_channels):
            var sum = 0.0
            for ic in range(in_channels):
                for kd in range(k_depth):
                    for kh in range(k_height):
                        for kw in range(k_width):
                            let in_idx = ic * depth * height * width + 
                                        (d + kd) * height * width + 
                                        (h + kh) * width + 
                                        (w + kw)
                            let k_idx = oc * in_channels * k_depth * k_height * k_width +
                                       ic * k_depth * k_height * k_width +
                                       kd * k_height * k_width +
                                       kh * k_width + kw
                            sum = sum + input[in_idx] * kernel[k_idx]
            output[oc * out_d * out_h * out_w + d * out_h * out_w + h * out_w + w] = sum

@entry
def main():
    let n = 1024 * 1024
    
    var a = @gpu_alloc(n * 4)
    var b = @gpu_alloc(n * 4)
    var c = @gpu_alloc(n * 4)
    
    @rocm_init()
    
    let start = @rocm_event()
    vector_add<<<4096, 256>>>(a, b, c, n)
    let end = @rocm_event()
    
    let elapsed = @rocm_elapsed(start, end)
    @println(f"Vector add took {} ms", elapsed)
    
    @rocm_cleanup()
    
    return 0
